{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b86804-a17e-4a79-be62-0e415591c4aa",
   "metadata": {},
   "source": [
    "### [Story](https://www.pivotaltracker.com/story/show/187949220)\n",
    "### [Source](https://medium.com/@prathammodi001/keras-cnn-tutorial-classifying-images-made-easy-fb55cc8892ec)\n",
    "\n",
    "Create from scratch a CNN apllied to computer vision, to classify cats and dogs from a well known image dataset published in [Kaggle](https://www.kaggle.com/c/dogs-vs-cats/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce25a0-082c-495f-bccc-6fad6968b910",
   "metadata": {},
   "source": [
    "## Dog Breed Classifier CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb4bd6-861c-4797-8fb2-433537ec45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2798507-df35-4d04-932d-f61e01565b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "if tf.config.list_logical_devices('GPU'):\n",
    "    print(\"Yes,  GPU available\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e993e45e-eca7-45b8-8da4-7720a16fb575",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bde157-8b97-44d0-96a9-9c26d40e369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "pd.set_option('display.max_columns', None) # show all columns\n",
    "pd.set_option('display.max.rows', None) # showw all rows\n",
    "\n",
    "labels_csv = pd.read_csv(\"./dataset/labels.csv\")\n",
    "labels_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619fdd13-81d5-4af7-b07d-8be77cb46cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA (exploratory data analysis)\n",
    "ax = labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10))\n",
    "\n",
    "average_value = labels_csv[\"breed\"].value_counts().mean()\n",
    "ax.axhline(average_value, color=\"red\", linestyle=\"--\", label=\"Average\")\n",
    "\n",
    "plt.xlabel(\"Brred\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Breed Distribution\")\n",
    "plt.legend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9626630-ed6a-46ff-918a-9feb1132a825",
   "metadata": {},
   "source": [
    "### Get images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc4d01-3d9b-4d62-b285-60540d06a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea5140-d2a0-472d-bc5e-e876c67a1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one image\n",
    "for image in labels_csv[\"id\"].head(1):\n",
    "    display(Image(filename=\"./dataset/train/\"+image+\".jpg\", width=300, height=\"300\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579fc59-f2e1-45cf-a008-6ba0593a6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get al images\n",
    "filenames = []\n",
    "for image_id in labels_csv[\"id\"]:\n",
    "    filenames.append(\"./dataset/train/\"+image_id+\".jpg\")\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f84b8c-a971-49e7-9132-6cf46e621a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all filenames of all images have been acquired\n",
    "if len(os.listdir(\"./dataset/train\")) == len(filenames):\n",
    "    print(\"Correct! Filenames match amount of files!\")\n",
    "else:\n",
    "    print(\"Error! Filenames do not match amount of files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736647e1-fbe9-40cf-8081-7af2402835b3",
   "metadata": {},
   "source": [
    "### labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d541c-c172-4393-a063-3d00f77beb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_csv[\"breed\"].to_numpy()\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22da729-112c-4318-9a5e-1742e9f33951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing data, lables or images\n",
    "if len(filenames) == len(labels):\n",
    "    print(\"No missing Data!\")\n",
    "else:\n",
    "    print(\"Missing data!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a12ef-6e85-480c-b97b-9a5d4181fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_breeds = labels\n",
    "labels[0] == unique_breeds\n",
    "\n",
    "boolean_labels = []\n",
    "\n",
    "for label in labels:\n",
    "    boolean_labels.append(label == unique_breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906b6cb-0353-47f1-b511-48cc1bd96dd4",
   "metadata": {},
   "source": [
    "## Prepare Train, Valid and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce215c39-2a6b-4d1a-81d9-e017c8c42894",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filenames\n",
    "y = boolean_labels\n",
    "\n",
    "NUM_IMAGES= 1000\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES], y[:NUM_IMAGES], test_size=0.2, random_state=42)\n",
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1139e8-61f9-4649-98e8-9fa6532c3d96",
   "metadata": {},
   "source": [
    "## Images to tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11225319-94f4-4707-a6e5-e1e96b7cd449",
   "metadata": {},
   "source": [
    "1. Take an image as input\n",
    "2. Use Tensorflow to read the file and save it to a variable `image`\n",
    "3. Turn the `image` (.jpeg) into Tensors\n",
    "4. Normalize the `image`\n",
    "5. Resize the `image` to 224x224\n",
    "6. Return the processed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adeb1f-19fa-4fc9-b84c-e9bdfb8db79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1\n",
    "image = plt.imread(filenames[42])\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b163f-b5bc-4b5f-a477-2db305b6da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2. \n",
    "tensor = tf.io.read_file(filenames[20])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa8274-2032-4f4f-89c3-aa55ac65b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3. Normalization: Turn image into numerical Tensor values: 0-255 (RGB)\n",
    "tensor = tf.image.decode_jpeg(tensor, channels=3)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e00943d9-7f49-486d-90b0-0fad26f25cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(375, 500, 3), dtype=float32, numpy=\n",
       "array([[[0.4901961 , 0.5019608 , 0.45882356],\n",
       "        [0.47450984, 0.48627454, 0.4431373 ],\n",
       "        [0.44705886, 0.47058827, 0.42352945],\n",
       "        ...,\n",
       "        [0.37647063, 0.48627454, 0.25490198],\n",
       "        [0.37254903, 0.48235297, 0.2509804 ],\n",
       "        [0.38823533, 0.49803925, 0.26666668]],\n",
       "\n",
       "       [[0.454902  , 0.4666667 , 0.42352945],\n",
       "        [0.43921572, 0.46274513, 0.4156863 ],\n",
       "        [0.427451  , 0.45098042, 0.4039216 ],\n",
       "        ...,\n",
       "        [0.36862746, 0.4784314 , 0.2392157 ],\n",
       "        [0.36078432, 0.47058827, 0.23137257],\n",
       "        [0.37254903, 0.48235297, 0.24313727]],\n",
       "\n",
       "       [[0.43921572, 0.46274513, 0.42352945],\n",
       "        [0.43137258, 0.46274513, 0.41960788],\n",
       "        [0.427451  , 0.45882356, 0.4156863 ],\n",
       "        ...,\n",
       "        [0.36078432, 0.47450984, 0.22352943],\n",
       "        [0.34509805, 0.45882356, 0.20784315],\n",
       "        [0.34901962, 0.46274513, 0.21176472]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.8941177 , 0.89019614, 0.882353  ],\n",
       "        [0.90196085, 0.8980393 , 0.89019614],\n",
       "        [0.909804  , 0.8941177 , 0.89019614],\n",
       "        ...,\n",
       "        [0.85098046, 0.83921576, 0.8196079 ],\n",
       "        [0.78823537, 0.77647066, 0.7568628 ],\n",
       "        [0.7411765 , 0.7294118 , 0.70980394]],\n",
       "\n",
       "       [[0.86666673, 0.86274517, 0.854902  ],\n",
       "        [0.91372555, 0.909804  , 0.90196085],\n",
       "        [0.9490197 , 0.9333334 , 0.9294118 ],\n",
       "        ...,\n",
       "        [0.86274517, 0.85098046, 0.8313726 ],\n",
       "        [0.8588236 , 0.8470589 , 0.82745105],\n",
       "        [0.8431373 , 0.8313726 , 0.8117648 ]],\n",
       "\n",
       "       [[0.93725497, 0.9333334 , 0.92549026],\n",
       "        [0.9215687 , 0.9176471 , 0.909804  ],\n",
       "        [0.8862746 , 0.8705883 , 0.86666673],\n",
       "        ...,\n",
       "        [0.8117648 , 0.8000001 , 0.7803922 ],\n",
       "        [0.83921576, 0.82745105, 0.8078432 ],\n",
       "        [0.83921576, 0.82745105, 0.8078432 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 4. : convert RGB numbers 0-255 into 0-1 for each RGB\n",
    "tf.image.convert_image_dtype(tensor, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "005d02fb-34e7-4f6d-9aea-4628cc35bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "# Takes an image file path and turns it into a Tensor\n",
    "def preprocess_image(image_path, img_size=IMG_SIZE):\n",
    "    # 1. read image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    # 2. turn it into numerical Tensor using 3 channels RGB\n",
    "    image = tf.image.decode_jpeg(image, cahnnels=3)\n",
    "    # 3. Normalize: convert 0-255 values into 0-1 for each RGB\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # 4. Resize to 224x224\n",
    "    image = tf.image.resize(image, size=[IMG_SIZE,IMG_SIZE])\n",
    "    # 5 return image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37af199-58d8-4b0e-8f7f-323f77d0c195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
