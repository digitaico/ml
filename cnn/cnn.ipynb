{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b86804-a17e-4a79-be62-0e415591c4aa",
   "metadata": {},
   "source": [
    "### [Story](https://www.pivotaltracker.com/story/show/187949220)\n",
    "### [Source](https://medium.com/@prathammodi001/keras-cnn-tutorial-classifying-images-made-easy-fb55cc8892ec)\n",
    "\n",
    "Create from scratch a CNN apllied to computer vision, to classify cats and dogs from a well known image dataset published in [Kaggle](https://www.kaggle.com/c/dogs-vs-cats/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce25a0-082c-495f-bccc-6fad6968b910",
   "metadata": {},
   "source": [
    "## Dog Breed Classifier CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb4bd6-861c-4797-8fb2-433537ec45cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2798507-df35-4d04-932d-f61e01565b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "if tf.config.list_logical_devices('GPU'):\n",
    "    print(\"Yes,  GPU available\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e993e45e-eca7-45b8-8da4-7720a16fb575",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bde157-8b97-44d0-96a9-9c26d40e369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "pd.set_option('display.max_columns', None) # show all columns\n",
    "pd.set_option('display.max.rows', None) # showw all rows\n",
    "\n",
    "labels_csv = pd.read_csv(\"./dataset/labels.csv\")\n",
    "labels_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619fdd13-81d5-4af7-b07d-8be77cb46cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA (exploratory data analysis)\n",
    "ax = labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20,10))\n",
    "\n",
    "average_value = labels_csv[\"breed\"].value_counts().mean()\n",
    "ax.axhline(average_value, color=\"red\", linestyle=\"--\", label=\"Average\")\n",
    "\n",
    "plt.xlabel(\"Brred\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Breed Distribution\")\n",
    "plt.legend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9626630-ed6a-46ff-918a-9feb1132a825",
   "metadata": {},
   "source": [
    "### Get images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc4d01-3d9b-4d62-b285-60540d06a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea5140-d2a0-472d-bc5e-e876c67a1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test one image\n",
    "for image in labels_csv[\"id\"].head(1):\n",
    "    display(Image(filename=\"./dataset/train/\"+image+\".jpg\", width=300, height=\"300\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579fc59-f2e1-45cf-a008-6ba0593a6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get al images\n",
    "filenames = []\n",
    "for image_id in labels_csv[\"id\"]:\n",
    "    filenames.append(\"./dataset/train/\"+image_id+\".jpg\")\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f84b8c-a971-49e7-9132-6cf46e621a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all filenames of all images have been acquired\n",
    "if len(os.listdir(\"./dataset/train\")) == len(filenames):\n",
    "    print(\"Correct! Filenames match amount of files!\")\n",
    "else:\n",
    "    print(\"Error! Filenames do not match amount of files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736647e1-fbe9-40cf-8081-7af2402835b3",
   "metadata": {},
   "source": [
    "### labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d541c-c172-4393-a063-3d00f77beb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels_csv[\"breed\"].to_numpy()\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22da729-112c-4318-9a5e-1742e9f33951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing data, lables or images\n",
    "if len(filenames) == len(labels):\n",
    "    print(\"No missing Data!\")\n",
    "else:\n",
    "    print(\"Missing data!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3a12ef-6e85-480c-b97b-9a5d4181fa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_breeds = labels\n",
    "labels[0] == unique_breeds\n",
    "\n",
    "boolean_labels = []\n",
    "\n",
    "for label in labels:\n",
    "    boolean_labels.append(label == unique_breeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906b6cb-0353-47f1-b511-48cc1bd96dd4",
   "metadata": {},
   "source": [
    "## Prepare Train, Valid and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce215c39-2a6b-4d1a-81d9-e017c8c42894",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filenames\n",
    "y = boolean_labels\n",
    "\n",
    "NUM_IMAGES= 1000\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES], y[:NUM_IMAGES], test_size=0.2, random_state=42)\n",
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1139e8-61f9-4649-98e8-9fa6532c3d96",
   "metadata": {},
   "source": [
    "## Images to tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11225319-94f4-4707-a6e5-e1e96b7cd449",
   "metadata": {},
   "source": [
    "1. Take an image as input\n",
    "2. Use Tensorflow to read the file and save it to a variable `image`\n",
    "3. Turn the `image` (.jpeg) into Tensors\n",
    "4. Normalize the `image`\n",
    "5. Resize the `image` to 224x224\n",
    "6. Return the processed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adeb1f-19fa-4fc9-b84c-e9bdfb8db79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1\n",
    "image = plt.imread(filenames[42])\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b163f-b5bc-4b5f-a477-2db305b6da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2. \n",
    "tensor = tf.io.read_file(filenames[20])\n",
    "#tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa8274-2032-4f4f-89c3-aa55ac65b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3. Normalization: Turn image into numerical Tensor values: 0-255 (RGB)\n",
    "tensor = tf.image.decode_jpeg(tensor, channels=3)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00943d9-7f49-486d-90b0-0fad26f25cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4. : convert RGB numbers 0-255 into 0-1 for each RGB\n",
    "tf.image.convert_image_dtype(tensor, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d02fb-34e7-4f6d-9aea-4628cc35bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "# Takes an image file path and turns it into a Tensor\n",
    "def preprocess_image(image_path, img_size=IMG_SIZE):\n",
    "    # 1. read image\n",
    "    image = tf.io.read_file(image_path)\n",
    "    # 2. turn it into numerical Tensor using 3 channels RGB\n",
    "    image = tf.image.decode_jpeg(image, cahnnels=3)\n",
    "    # 3. Normalize: convert 0-255 values into 0-1 for each RGB\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # 4. Resize to 224x224\n",
    "    image = tf.image.resize(image, size=[IMG_SIZE,IMG_SIZE])\n",
    "    # 5 return image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37af199-58d8-4b0e-8f7f-323f77d0c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size data: function to return a tuple (image, label)\n",
    "def get_image_label(image_path, label):\n",
    "    image = preprocess_image(image_path)\n",
    "    return image, label   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c843d-f122-49a7-be2d-75144348532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\"\"\" Creates batches of data out of image (X) and lable (y) pairs\"\"\"\n",
    "def create_batches(X, y=None, batch_size = BATCH_SIZE, valid_data = False, test_data = False):\n",
    "    if test_data: # NO labels\n",
    "        print(\"Creating Test data Batches...\")\n",
    "        data_whole = tf.data.Dataset.from_tensor_slices((tf.constant(X),))\n",
    "        data_batch = data_whole.map(preprocess_image).batch(BATCH_SIZE)\n",
    "        return data_batch\n",
    "\n",
    "    elif valid_data: \n",
    "        print(\"Creating Valid Data batches...\")\n",
    "        data_whole = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "        data_batch = data_whole.map(get_image_label).batch(BATCH_SIZE)\n",
    "        return data_batch\n",
    "    else: # Trainig set\n",
    "        print(\"Creating Training Data Batches...\")\n",
    "        data_whole = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
    "        data_batch = data_whole.shuffle(buffer_size=len(X)).map(get_image_label).batch(BATCH_SIZE)\n",
    "        return data_batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd1a9a-4d0f-4364-a519-53ef5ac8b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_batches(X_train, y_train)\n",
    "val_data = create_batches(X_val, y_val, valid_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867aa5c9-0b6b-4325-b1fc-a83bee3e4e88",
   "metadata": {},
   "source": [
    "### Visualize Data Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1690d5-09bf-4ab4-878f-8fa8c0050dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
